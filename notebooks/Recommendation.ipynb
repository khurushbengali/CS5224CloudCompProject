{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9383f7f9-43f2-4f02-bf56-32bcd57a186e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ccd6e4-18c7-49a0-80a6-7d8d726a4fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = pd.read_csv('df_filter.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b5a021ee-da92-4c02-bf1b-13ab7ebf75fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1654fa31-623d-44f9-89ad-cb121fbffc32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\13808\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\13808\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\13808\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\13808\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c207a083-bf5e-41b8-b627-763456440c36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7fd7d9f4-2c40-4b5c-9791-bd55c3a5a247",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    additional_stopwords = {'translate', 'translation', 'already'}\n",
    "    stop_words = stop_words.union(additional_stopwords)\n",
    "    punctuation = set(string.punctuation)\n",
    "    months = [\"January\", \"February\", \"March\", \"April\", \"May\", \"June\", \n",
    "              \"July\", \"August\", \"September\", \"October\", \"November\", \"December\",\n",
    "              \"Jan\", \"Feb\", \"Mar\", \"Apr\", \"Jun\", \"Jul\", \"Aug\", \"Sep\", \"Sept\", \"Oct\", \"Nov\", \"Dec\"]\n",
    "    months_regex = r'\\b(?:' + '|'.join(months) + r')\\.?\\b'\n",
    "\n",
    "    text = re.sub(months_regex, '', text)\n",
    "    text = re.sub(r'\\b\\d+\\b', '', text)\n",
    "    text = text.replace('./', '')\n",
    "    text = text.replace('./', '')\n",
    "    \n",
    "    words = word_tokenize(text)\n",
    "    filtered_text = ' '.join([word for word in words if word.lower() not in stop_words and word not in punctuation])\n",
    "    return filtered_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "275bce47-ad02-4641-9f03-32905dd5acf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter['title'] = df_filter['title'].apply(lambda x: remove_stopwords(x) if isinstance(x, str) else x)\n",
    "df_filter['alternative_title'] = df_filter['alternative_title'].apply(lambda x: remove_stopwords(x) if isinstance(x, str) else x)\n",
    "df_filter['abstract'] = df_filter['abstract'].apply(lambda x: remove_stopwords(x) if isinstance(x, str) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5dbb6abc-756a-4189-ac36-9b4f76b8b746",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filter = df_filter.fillna(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "22508ee1-1ae9-4c1f-ab69-cefbf629f9c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2vec pretrain model\n",
    "# https://code.google.com/archive/p/word2vec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2fd03053-7d2d-44a4-99bd-fbbc9a92b576",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "\n",
    "wv = gensim.models.KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin\", binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ccb2c0d1-bbf3-4507-b613-674eb1303bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def recommendation(input_uuid):\n",
    "    input_row = df_filter[df_filter['identifier_uuid'] == input_uuid].to_numpy()\n",
    "\n",
    "    if len(input_row) == 0:\n",
    "        print(f\"No book found with UUID: {input_uuid}\")\n",
    "        return []\n",
    "\n",
    "    matrix_input_title_vocab = []\n",
    "    for list_ in input_row:\n",
    "        title_words = [word for word in list_[1].split() if word in wv.vocab] if isinstance(list_[1], str) else []\n",
    "        alt_title_words = [word for word in list_[2].split() if word in wv.vocab] if isinstance(list_[2], str) else []\n",
    "        abstract_words = [word for word in list_[3].split() if word in wv.vocab] if isinstance(list_[3], str) else []\n",
    "        matrix_input_title_vocab.append([list_[0], title_words, alt_title_words, abstract_words])\n",
    "\n",
    "    matrix_similarity = []\n",
    "\n",
    "    for list1 in df_filter.to_numpy():\n",
    "        if list1[0] == input_uuid:  \n",
    "            continue\n",
    "\n",
    "        list1_title_words = [word for word in list1[1].split() if word in wv.vocab] if isinstance(list1[1], str) else []\n",
    "        list1_alt_title_words = [word for word in list1[2].split() if word in wv.vocab] if isinstance(list1[2], str) else []\n",
    "        list1_abstract_words = [word for word in list1[3].split() if word in wv.vocab] if isinstance(list1[3], str) else []\n",
    "\n",
    "        for list2 in matrix_input_title_vocab:\n",
    "            score_title = score_alt_title = score_abstract = 0\n",
    "\n",
    "            if list1_title_words and list2[1]:\n",
    "                score_title = wv.n_similarity(list1_title_words, list2[1])\n",
    "            if list1_alt_title_words and list2[2]:\n",
    "                score_alt_title = wv.n_similarity(list1_alt_title_words, list2[2])\n",
    "            if list1_abstract_words and list2[3]:\n",
    "                score_abstract = wv.n_similarity(list1_abstract_words, list2[3])\n",
    "\n",
    "            score_max_title = max(score_title, score_alt_title)\n",
    "            final_score = score_max_title + score_abstract\n",
    "            matrix_similarity.append([list1[0], final_score])\n",
    "\n",
    "    sorted_similarities = sorted(matrix_similarity, key=lambda x: x[1], reverse=True)[:10]\n",
    "\n",
    "    recommended_uuids = [uuid for uuid, score in sorted_similarities]\n",
    "    return recommended_uuids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6eb1996-7327-4582-b24f-86725aeedb42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['020c14b6-c11f-4ead-b8b6-6b3a4e4073b3',\n",
       " '2fefcf62-1443-4b88-8ae8-4776f6495776',\n",
       " '3fbedac9-6a0c-4af3-9024-e603515023f3',\n",
       " '5062c101-452c-489e-8458-778c29d733b4',\n",
       " '64bd8e06-de2b-4f77-8ebe-4377226a7535',\n",
       " '693e2428-08e1-4970-89cb-1f1071a68330',\n",
       " '8a972717-f82c-45e3-8eb7-ddb3d06bfa38',\n",
       " '8afa792e-9033-40ae-917a-c59454e7766c',\n",
       " '8bdc72b1-a2da-404e-920a-6d8b485e0dd6',\n",
       " '9b0af09d-c80a-4322-9f02-7d623da1ef0a']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendation('000032e8-b5d5-43a1-8f0b-e410327580b6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97974857-58f7-462a-922b-82765f313a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def calculate_similarity_matrices(df):\n",
    "    df = df.reset_index(drop=True)\n",
    "    num_books = len(df)\n",
    "\n",
    "    title_matrix = np.zeros((num_books, num_books))\n",
    "    alt_title_matrix = np.zeros((num_books, num_books))\n",
    "    abstract_matrix = np.zeros((num_books, num_books))\n",
    "\n",
    "    titles = [np.array([wv[word] for word in title.split() if word in wv.vocab]) for title in df['title'].fillna('')]\n",
    "    alt_titles = [np.array([wv[word] for word in alt_title.split() if word in wv.vocab]) for alt_title in df['alternative_title'].fillna('')]\n",
    "    abstracts = [np.array([wv[word] for word in abstract.split() if word in wv.vocab]) for abstract in df['abstract'].fillna('')]\n",
    "\n",
    "    def average_vector(vectors):\n",
    "        if len(vectors) == 0:\n",
    "            return np.zeros(300)\n",
    "        return np.mean(vectors, axis=0)\n",
    "\n",
    "    for i in tqdm(range(num_books)):\n",
    "        for j in range(i, num_books):\n",
    "            avg_vec_i_title = average_vector(titles[i])\n",
    "            avg_vec_j_title = average_vector(titles[j])\n",
    "            avg_vec_i_alt_title = average_vector(alt_titles[i])\n",
    "            avg_vec_j_alt_title = average_vector(alt_titles[j])\n",
    "            avg_vec_i_abstract = average_vector(abstracts[i])\n",
    "            avg_vec_j_abstract = average_vector(abstracts[j])\n",
    "\n",
    "            title_similarity = np.dot(avg_vec_i_title, avg_vec_j_title) / (np.linalg.norm(avg_vec_i_title) * np.linalg.norm(avg_vec_j_title) + 1e-10)\n",
    "            title_matrix[i, j] = title_matrix[j, i] = title_similarity\n",
    "\n",
    "            alt_title_similarity = np.dot(avg_vec_i_alt_title, avg_vec_j_alt_title) / (np.linalg.norm(avg_vec_i_alt_title) * np.linalg.norm(avg_vec_j_alt_title) + 1e-10)\n",
    "            alt_title_matrix[i, j] = alt_title_matrix[j, i] = alt_title_similarity\n",
    "\n",
    "            abstract_similarity = np.dot(avg_vec_i_abstract, avg_vec_j_abstract) / (np.linalg.norm(avg_vec_i_abstract) * np.linalg.norm(avg_vec_j_abstract) + 1e-10)\n",
    "            abstract_matrix[i, j] = abstract_matrix[j, i] = abstract_similarity\n",
    "\n",
    "    return title_matrix, alt_title_matrix, abstract_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3da3915a-aaae-4c23-81d4-47b950abd6d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████| 42261/42261 [20:47:28<00:00,  1.77s/it]\n"
     ]
    }
   ],
   "source": [
    "title_matrix, alt_title_matrix, abstract_matrix = calculate_similarity_matrices(df_filter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fc32ae9f-2a20-41c3-acc7-6c724db99102",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_recommendations(title_matrix, alt_title_matrix, abstract_matrix, top_n=10):\n",
    "    num_books = title_matrix.shape[0]\n",
    "    top_recommendations = {}\n",
    "\n",
    "    for i in range(num_books):\n",
    "        scores = np.maximum(title_matrix[i], alt_title_matrix[i]) + abstract_matrix[i]\n",
    "        scores[i] = -np.inf\n",
    "        top_indices = np.argpartition(scores, -top_n)[-top_n:]\n",
    "        top_indices = top_indices[np.argsort(-scores[top_indices])]\n",
    "        top_recommendations[i] = [(index, scores[index]) for index in top_indices]\n",
    "\n",
    "    return top_recommendations\n",
    "\n",
    "recommendations = get_top_recommendations(title_matrix, alt_title_matrix, abstract_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b8ea303a-8873-458b-9d24-69372b3a1688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(34274, 1.9556227562495014),\n",
       " (39748, 1.955416939265599),\n",
       " (39856, 1.95190068252902),\n",
       " (13258, 1.951762379952316),\n",
       " (41649, 1.9515244518848027),\n",
       " (41827, 1.9514178615534066),\n",
       " (8560, 1.9513294376520687),\n",
       " (38548, 1.9493518347922212),\n",
       " (8910, 1.9488663768467793),\n",
       " (6417, 1.9472349684426402)]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendations[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d0132ae1-980a-4761-be3e-d1a2ae9ab9bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['00000c04-4b98-4c0f-935f-3e9227cd71bb', 'Original report',\n",
       "       'Primary production bulletin',\n",
       "       \"`` Origin Bulletin '' monthly publication Singapore Agri-Food Veterinary Authority introducing technical knowledge agriculture animal husbandry guiding application agricultural science management knowledge 66th issue content including quail breeding agricultural Q flower cultivation Newcastle disease poultry\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filter.to_numpy()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b904e9e6-a5fb-4e54-a6f7-771de7a67e21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['299d8cb4-f571-41f5-9cd2-ac000c694b51', 'Original report',\n",
       "       'Primary production bulletin Village produce news Primary produce report',\n",
       "       \"`` 'Origin Report monthly publication Singapore Agri-Food Veterinary Authority introducing technical knowledge agriculture animal husbandry guiding application agricultural science management knowledge 41st issue content including tomato cultivation new agricultural knowledge agricultural Q prevention piglet diseases introduction dairy cows ''\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_filter.to_numpy()[6417]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40a0d746-408d-417f-a07a-87871d971cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import json\n",
    "\n",
    "np.save('title_matrix.npy', title_matrix)\n",
    "np.save('alt_title_matrix.npy', alt_title_matrix)\n",
    "np.save('abstract_matrix.npy', abstract_matrix)\n",
    "\n",
    "with open('recommendations.json', 'w') as f:\n",
    "    recommendations_to_save = {str(k): [(int(index), float(score)) for index, score in v] for k, v in recommendations.items()}\n",
    "    json.dump(recommendations_to_save, f, indent=4)\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (py312)",
   "language": "python",
   "name": "py312"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
